import os
import re
from typing import List
from dotenv import load_dotenv
from langchain_text_splitters import RecursiveCharacterTextSplitter

load_dotenv()

class TextProcessor:
    DEFAULT_CHUNK_SIZE = int(os.getenv("TEXT_CHUNK_SIZE", "1000"))
    DEFAULT_CHUNK_OVERLAP = int(os.getenv("TEXT_CHUNK_OVERLAP", "200"))

    def __init__(self, embeddings_client=None):
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.DEFAULT_CHUNK_SIZE,
            chunk_overlap=self.DEFAULT_CHUNK_OVERLAP,
            length_function=len,
            is_separator_regex=False,
            separators=["\n\n", "\n", ". ", " ", ""],
        )
        print(f"TextProcessor initialized with RecursiveCharacterTextSplitter (chunk_size={self.DEFAULT_CHUNK_SIZE}, chunk_overlap={self.DEFAULT_CHUNK_OVERLAP})")

    def clean_text(self, text: str) -> str:
        text = re.sub(r'(\w+)\s*-\s*\n\s*(\w+)', r'\1\2', text)
        text = re.sub(r'(\w+)\s*-\s*(\w+)', r'\1-\2', text)

        text = re.sub(
            r'\b(\d)(\d)\s+(minute|second|hour)(s?)\b',
            lambda m: f"{m.group(1)}-{m.group(2)} {m.group(3)}{m.group(4)}",
            text
        )
        text = re.sub(r'\b6-0\s+seconds\b', '60 seconds', text, flags=re.IGNORECASE)

        replacements = {
            r'\bsurvival[-\s]*focussed\b': 'survival-focused',
            r'\b(?:comfort[-\s]*focussed|co\s*mfort[-\s]*focussed)\b': 'comfort-focused',
            r'\bextrem[-\s]*ely\b': 'extremely',
            r'\bgestat[-\s]*ion\b': 'gestation',
            r'\bneonata[-\s]*l\b': 'neonatal',
            r'\bpre[-\s]*hospital\b': 'pre-hospital',
            r'\batt[-\s]*endance\b': 'attendance',
            r'\btransitto\b': 'transit to',
            r'\bwiththe\b': 'with the',
            r'\bthebaby\b': 'the baby',
            r'\binterventionsfocussed\b': 'interventions focused',
            r'\bhelpto\b': 'help to',
            r'\bkeepthe\b': 'keep the',
            r'\bwillbe\b': 'will be',
            r'\bcanbe\b': 'can be',
            r'\baboutsignsof\b': 'about signs of',
            r'\bhelpis\b': 'help is',
            r'\bfromthe\b': 'from the',
            r'\bofa\b': 'of a',
            r'\btoa\b': 'to a',
            r'\bina\b': 'in a',
            r'\basa\b': 'as a',
            r'\bisa\b': 'is a',
            r'\bita\b': 'it a',
            r'\bintoa\b': 'into a',
            r'\bontoa\b': 'onto a',
            r'\b(?:fr\s*om|fro\s*m)\b': 'from',
            r'\b(?:wi\s*th|wit\s*h)\b': 'with',
            r'\b(?:th\s*an|tha\s*n)\b': 'than',
            r'\b(?:th\s*en|the\s*n)\b': 'then',
            r'\b(?:wh\s*en|whe\s*n)\b': 'when',
        }
        for pattern, replacement in replacements.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)

        text = re.sub(r'\s+([.,:;])\s*', r'\1 ', text)
        text = re.sub(r'[ \t]+', ' ', text)
        text = re.sub(r'\n{3,}', '\n\n', text)
        text = re.sub(r'===== Page \d+ =====', '\n\n', text)
        text = re.sub(r'Page \d+', '', text)

        return text.strip()

    def process_text(self, text: str, verbose: bool = False) -> List[str]:
        cleaned_text = self.clean_text(text)

        if verbose:
            print("--- Cleaned Text Sample ---")
            print(cleaned_text[:500] + "\n...")

        try:
            chunks = self.splitter.split_text(cleaned_text)
            chunks = [c.strip() for c in chunks if c.strip()]
        except Exception as e:
             print(f"ERROR during Recursive Character Splitting: {e}")
             chunks = []

        if verbose:
            print(f"\nTotal chunks generated by RecursiveCharacterTextSplitter: {len(chunks)}")
            if chunks:
                lengths = [len(c) for c in chunks]
                avg_len = sum(lengths) / len(lengths) if lengths else 0
                min_len = min(lengths) if lengths else 0
                max_len = max(lengths) if lengths else 0
                print(f"Chunk length stats: Avg={avg_len:.0f}, Min={min_len}, Max={max_len}")
                print("Sample chunk:", chunks[0][:200] + "...")
            else:
                 print("No chunks generated by RecursiveCharacterTextSplitter.")

        return chunks